{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "\n",
    "data_path='Dataset/'\n",
    "categories=os.listdir(data_path)\n",
    "labels=[i for i in range(len(categories))]\n",
    "\n",
    "label_dict=dict(zip(categories,labels)) #empty dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=100\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    folder_path=os.path.join(data_path,category)\n",
    "    img_names=os.listdir(folder_path)\n",
    "        \n",
    "    for img_name in img_names:\n",
    "        img_path=os.path.join(folder_path,img_name)\n",
    "        imgs=cv2.imread(img_path)\n",
    "\n",
    "        try:\n",
    "            gray=cv2.cvtColor(imgs,cv2.COLOR_BGR2GRAY)           \n",
    "            #Coverting the image into gray scale\n",
    "            resized=cv2.resize(gray,(img_size,img_size))\n",
    "            #resizing the gray scale into 50x50, since we need a fixed common size for all the images in the dataset\n",
    "            data.append(resized)\n",
    "            labels.append(label_dict[category])\n",
    "            #appending the image and the label(categorized) into the list (dataset)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Exception:',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "data=np.array(data)/255.0\n",
    "data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n",
    "target=np.array(target)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "new_target=np_utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data',data)\n",
    "np.save('target',new_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data=np.load('data.npy')\n",
    "target=np.load('target.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The first CNN layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Conv2D(100,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The second convolution layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from second convolution layer\n",
    "model.add(Dense(50,activation='relu'))\n",
    "#Dense layer of 64 neurons\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "#The Final layer with two outputs for two categories\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.9079 - accuracy: 0.5070 - val_loss: 0.6575 - val_accuracy: 0.6498\n",
      "INFO:tensorflow:Assets written to: my_model-001.model\\assets\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 43s 1s/step - loss: 0.6175 - accuracy: 0.6704 - val_loss: 0.4707 - val_accuracy: 0.8481\n",
      "INFO:tensorflow:Assets written to: my_model-002.model\\assets\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 49s 2s/step - loss: 0.4426 - accuracy: 0.8203 - val_loss: 0.3377 - val_accuracy: 0.9198\n",
      "INFO:tensorflow:Assets written to: my_model-003.model\\assets\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.3363 - accuracy: 0.8768 - val_loss: 0.2666 - val_accuracy: 0.9114\n",
      "INFO:tensorflow:Assets written to: my_model-004.model\\assets\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.2726 - accuracy: 0.8851 - val_loss: 0.2598 - val_accuracy: 0.9030\n",
      "INFO:tensorflow:Assets written to: my_model-005.model\\assets\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.2277 - accuracy: 0.9040 - val_loss: 0.2561 - val_accuracy: 0.9030\n",
      "INFO:tensorflow:Assets written to: my_model-006.model\\assets\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.1637 - accuracy: 0.9436 - val_loss: 0.2328 - val_accuracy: 0.9072\n",
      "INFO:tensorflow:Assets written to: my_model-007.model\\assets\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.1364 - accuracy: 0.9576 - val_loss: 0.2539 - val_accuracy: 0.9198\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 53s 2s/step - loss: 0.1223 - accuracy: 0.9492 - val_loss: 0.2170 - val_accuracy: 0.9156\n",
      "INFO:tensorflow:Assets written to: my_model-009.model\\assets\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.1325 - accuracy: 0.9468 - val_loss: 0.2513 - val_accuracy: 0.9072\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 53s 2s/step - loss: 0.0820 - accuracy: 0.9702 - val_loss: 0.2148 - val_accuracy: 0.9283\n",
      "INFO:tensorflow:Assets written to: my_model-011.model\\assets\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0681 - accuracy: 0.9773 - val_loss: 0.2924 - val_accuracy: 0.8945\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0847 - accuracy: 0.9724 - val_loss: 0.2252 - val_accuracy: 0.9198\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0686 - accuracy: 0.9715 - val_loss: 0.2367 - val_accuracy: 0.9241\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.2523 - val_accuracy: 0.9325\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0659 - accuracy: 0.9755 - val_loss: 0.2559 - val_accuracy: 0.9283\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0475 - accuracy: 0.9846 - val_loss: 0.2729 - val_accuracy: 0.9072\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 53s 2s/step - loss: 0.0850 - accuracy: 0.9702 - val_loss: 0.5084 - val_accuracy: 0.8481\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0993 - accuracy: 0.9611 - val_loss: 0.2226 - val_accuracy: 0.9325\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 52s 2s/step - loss: 0.0786 - accuracy: 0.9681 - val_loss: 0.2350 - val_accuracy: 0.9283\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('my_model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 341ms/step - loss: 0.1036 - accuracy: 0.9621\n",
      "[0.10364756733179092, 0.9621211886405945]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(test_data,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model-011.h5')\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") \n",
    "source=cv2.VideoCapture(2)\n",
    "\n",
    "labels_dict={0:'with_mask',1:'without_mask'}\n",
    "color_dict={0:(0,255,0),1:(0,0,255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n",
      "Face not detected\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "path =  \"haarcascade_frontalface_default.xml\"\n",
    "font_scale = 1.5\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "rectangle_bgr = (255,255,255)\n",
    "\n",
    "img = np.zeros((500,500))\n",
    "\n",
    "text = \"Some text in a box\"\n",
    "\n",
    "(text_width,text_height) = cv2.getTextSize(text , font, fontScale = font_scale , thickness=1)[0]\n",
    "\n",
    "text_offset_x = 10\n",
    "text_offset_y = img.shape[0] -25\n",
    "\n",
    "box_coords = ((text_offset_x,text_offset_y),(text_offset_x + text_width + 2 , text_offset_y - text_height -2))\n",
    "cv2.rectangle(img , box_coords[0] , box_coords[1], rectangle_bgr , cv2.FILLED)\n",
    "cv2.putText(img , text ,(text_offset_x,text_offset_y),font , fontScale=font_scale,color=(0,0,0), thickness=1 )\n",
    "\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOEerror(\"cannot open webcam\")\n",
    "    \n",
    "\n",
    "while True:\n",
    "    imgs = vs.read()\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") \n",
    "    gray = cv2.cvtColor(imgs,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,1.1,4)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_Color = imgs[y:y+h,x:x+w]\n",
    "        cv2.rectangle(imgs ,(x,y),(x+w,y+h) ,(255,0,0), 2)\n",
    "        faces = faceCascade.detectMultiScale(roi_gray)\n",
    "        if(len(faces) ==0):\n",
    "            print(\"Face not detected\")\n",
    "        else:\n",
    "            for (ex,ey,ew,eh) in faces:\n",
    "                face_roi = roi_Color[ey: ey+eh ,ex:ex + ew]\n",
    "    final_image = cv2.resize(face_roi,(224,224))\n",
    "    final_image = np.expand_dims(final_image,axis=0) #need 4th dimens\n",
    "    final_image = final_image/255.0\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    Predictions = model.predict(final_image)\n",
    "    font_scale = 1.5\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    \n",
    "    if(Predictions>0):\n",
    "        status = \"No Mask\"\n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        cv2.rectangle(imgs ,(x1,y1),(x1+w,y1+h) ,(0,0,0), -1)\n",
    "        \n",
    "        cv2.putText(imgs,status,(x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2 )\n",
    "        cv2.putText(imgs,status, (100,150),font, 3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(imgs,(x,y),(x+w,y+h),(0,0,255) )\n",
    "    else:\n",
    "        status = \"Face Mask\"\n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        cv2.rectangle(imgs ,(x1,y1),(x1+w,y1+h) ,(0,0,0), -1)\n",
    "        \n",
    "        cv2.putText(imgs,status,(x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2 )\n",
    "        cv2.putText(imgs,status, (100,150),font, 3,(0,255,0),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(imgs,(x,y),(x+w,y+h),(0,255,0) )\n",
    "        \n",
    "    cv2.imshow(\"face mask project\",imgs)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 224, 224, 3), found shape=(None, 100, 100, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c1ced808de88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mnormalized\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mreshaped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\sirepandey\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_1: expected shape=(None, 224, 224, 3), found shape=(None, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "\n",
    "while(True):\n",
    "\n",
    "    img = vs.read()\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceCascade.detectMultiScale(gray,1.3,5)  \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img=gray[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face_img,(100,100))\n",
    "        normalized=resized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,100,100,1))\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color_dict[label],2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),color_dict[label],-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<class 'cv2.CascadeClassifier'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\core\\src\\persistence.cpp:717: error: (-49:Unknown error code -49) Input file is invalid in function 'cv::FileStorage::Impl::open'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-10761d8d6e9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"my_model_10.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mfaceCascade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"haarcascade_frontalface_default.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mvideo_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class 'cv2.CascadeClassifier'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from imutils.video import VideoStream\n",
    "vs = VideoStream(src=0).start()\n",
    "    \n",
    "\n",
    "model = load_model(\"my_model_10.h5\")\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") \n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret,frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    faces_list=[]\n",
    "    preds=[]\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_frame = frame[y:y+h,x:x+w]\n",
    "        face_frame = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
    "        face_frame = cv2.resize(face_frame, (224, 224))\n",
    "        face_frame = img_to_array(face_frame)\n",
    "        face_frame = np.expand_dims(face_frame, axis=0)\n",
    "        face_frame =  preprocess_input(face_frame)\n",
    "        faces_list.append(face_frame)\n",
    "        if len(faces_list)>0:\n",
    "            preds = model.predict(faces_list)\n",
    "        for pred in preds:\n",
    "            (mask, withoutMask) = pred\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "        cv2.putText(frame, label, (x, y- 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    " \n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h),color, 2)\n",
    "        # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-73cfa4811cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     faces = faceCascade.detectMultiScale(gray,\n\u001b[0m\u001b[0;32m      6\u001b[0m                                          \u001b[0mscaleFactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                          \u001b[0mminNeighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x0000027FFADE1810>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-722a596efccb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimagePath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# load the input image (224x224) and preprocess it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[0;32m    300\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2941\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2942\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2943\u001b[1;33m     raise UnidentifiedImageError(\n\u001b[0m\u001b[0;32m   2944\u001b[0m         \u001b[1;34m\"cannot identify image file %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m     )\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x0000027FFADE1810>"
     ]
    }
   ],
   "source": [
    "imagePaths = list(paths.list_images(\"Dataset\"))\n",
    "data = []\n",
    "labels = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\t# load the input image (224x224) and preprocess it\n",
    "\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\timage = preprocess_input(image)\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_shape=(224, 224, 3))\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training head...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (224, 224, 3), y.shape = (504, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a155d2388433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training head...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m H = model.fit(\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0maug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m     \"\"\"\n\u001b[1;32m--> 853\u001b[1;33m     return NumpyArrayIterator(\n\u001b[0m\u001b[0;32m    854\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     super(NumpyArrayIterator, self).__init__(\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             raise ValueError('`x` (images tensor) and `y` (labels) '\n\u001b[0m\u001b[0;32m     87\u001b[0m                              \u001b[1;34m'should have the same length. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                              \u001b[1;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (224, 224, 3), y.shape = (504, 1)"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 1\n",
    "BS = 32\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
